{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Reading Data in Dataframe \n",
    "Now we will be reading data from \"Loan.csv\" to Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->Read Chunk... 1\n",
      "-->Read Chunk... 2\n",
      "-->Read Chunk... 3\n",
      "-->Read Chunk... 4\n",
      "-->Read Chunk... 5\n",
      "-->Read Chunk... 6\n",
      "-->Read Chunk... 7\n",
      "-->Read Chunk... 8\n",
      "-->Read Chunk... 9\n",
      "-->Read Chunk... 10\n",
      "-->Read Chunk... 11\n",
      "-->Read Chunk... 12\n"
     ]
    }
   ],
   "source": [
    "file1 = \"../data/raw/loan.csv\"\n",
    "ChunkSize = 200000\n",
    "i = 1\n",
    "for chunk in pd.read_csv(file1, chunksize=ChunkSize, low_memory=False):\n",
    "    loan_data = chunk if i == 1 else pd.concat([loan_data, chunk])\n",
    "    print('-->Read Chunk...', i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Checking data size \n",
    "Let's quickly check the shape of data.This will give us idea as how large is current dataset. As we can see, current data set contains more than 2 million rows and 145 columns. Not all columns are useful for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260668, 145)\n"
     ]
    }
   ],
   "source": [
    "# print(list(data.columns))\n",
    "print(loan_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Calculating Percentage of missing data per column \n",
    "Here we will be creating Dataframe called \"df_null\". This Data frame consist of column name with percent of missing data in each column in descending order. It is noted that any column that has more than 60% of data missing are useless for our analysis and we will simply drop it. As we see some column like \"url\", \"id\", \"member_id\" has 100% missing values. Apart from that lot of columns have more than 60% missing data. We will simply drop column which has more than 60% data missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Count  Percent\n",
      "id                                          2260668    100.0\n",
      "url                                         2260668    100.0\n",
      "member_id                                   2260668    100.0\n",
      "orig_projected_additional_accrued_interest  2252242     99.6\n",
      "hardship_dpd                                2250055     99.5\n",
      "hardship_length                             2250055     99.5\n",
      "hardship_reason                             2250055     99.5\n",
      "hardship_status                             2250055     99.5\n",
      "deferral_term                               2250055     99.5\n",
      "hardship_amount                             2250055     99.5\n",
      "hardship_start_date                         2250055     99.5\n",
      "hardship_end_date                           2250055     99.5\n",
      "payment_plan_start_date                     2250055     99.5\n",
      "hardship_loan_status                        2250055     99.5\n",
      "hardship_type                               2250055     99.5\n",
      "hardship_payoff_balance_amount              2250055     99.5\n",
      "hardship_last_payment_amount                2250055     99.5\n",
      "settlement_amount                           2227612     98.5\n",
      "debt_settlement_flag_date                   2227612     98.5\n",
      "settlement_status                           2227612     98.5\n",
      "settlement_date                             2227612     98.5\n",
      "settlement_percentage                       2227612     98.5\n",
      "settlement_term                             2227612     98.5\n",
      "sec_app_mths_since_last_major_derog         2224726     98.4\n",
      "sec_app_revol_util                          2154484     95.3\n",
      "revol_bal_joint                             2152648     95.2\n",
      "sec_app_open_act_il                         2152647     95.2\n",
      "sec_app_num_rev_accts                       2152647     95.2\n",
      "sec_app_open_acc                            2152647     95.2\n",
      "sec_app_mort_acc                            2152647     95.2\n",
      "sec_app_inq_last_6mths                      2152647     95.2\n",
      "sec_app_earliest_cr_line                    2152647     95.2\n",
      "sec_app_chargeoff_within_12_mths            2152647     95.2\n",
      "sec_app_collections_12_mths_ex_med          2152647     95.2\n",
      "verification_status_joint                   2144938     94.9\n",
      "dti_joint                                   2139962     94.7\n",
      "annual_inc_joint                            2139958     94.7\n",
      "desc                                        2134601     94.4\n",
      "mths_since_last_record                      1901512     84.1\n",
      "mths_since_recent_bc_dlq                    1740967     77.0\n",
      "mths_since_last_major_derog                 1679893     74.3\n",
      "mths_since_recent_revol_delinq              1520309     67.3\n"
     ]
    }
   ],
   "source": [
    "# print((data.isna().sum()[data.isna().sum() > 0]))\n",
    "df_null = pd.DataFrame({'Count': loan_data.isnull().sum(), 'Percent': 100*loan_data.isnull().sum()/len(loan_data)})\n",
    "print(df_null[df_null['Percent'] >= 60].sort_values(by='Percent', ascending=False).round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Dropping column with more than 60% missing data \n",
    "We will create a list of columns that a data missing more than 60%. We will simply drop those columns and create new dataframe called df_clean. We wil print shape of new dataframe to see how much data has been reduced. We can see total count of columns from 145 to reduced to 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "(2260668, 103)\n"
     ]
    }
   ],
   "source": [
    "# Creating list of column with more than 60% data missing. \n",
    "list_60 = list(df_null[df_null['Percent']>60].index)\n",
    "\n",
    "print(len(list_60))\n",
    "df_clean = loan_data.drop(list_60, axis=1)\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_clean.sample(frac= 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv('../data/raw/loan_sample.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
